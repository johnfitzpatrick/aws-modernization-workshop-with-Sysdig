[
{
	"uri": "//localhost:1313/10_prerequisites/14_self_paced/account.html",
	"title": "Create an AWS account",
	"tags": [],
	"description": "",
	"content": " Your account must have the ability to create new IAM roles and scope other IAM permissions.\n  If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now by clicking here\n Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n Enter the user details:  Attach the AdministratorAccess IAM Policy:  Click to create the new user:  Take note of the login URL and save:   "
},
{
	"uri": "//localhost:1313/",
	"title": "Main Page",
	"tags": [],
	"description": "",
	"content": " AWS Security with Sysdig Welcome Welcome to the AWS Security with Sysdig hands-on workshop.\nIn this workshop, you will learn how to securely run cloud applications in production by automating AWS Fargate and ECR image scanning directly in your AWS environment.\nYou will also discover how to improve the security of your cloud infrastructure using AWS CloudTrail and Sysdig Cloud Connector. So not only are the applications secure, but so is the cloud infrastructure on which they depend!\nObjectives The objective of this workshop is to familiarize users with the installation, configuration and usage of the following Sysdig security tools specific to AWS:\n Amazon ECR image scanning\n Amazon Fargate automatic image scanning\n Amazon CloudTrail runtime security\n  Who should take this workshop?  Infrastructure Engineers\n DevOps Engineers\n Solutions Architects  Software Developers\n SREs\n Technical leads\n  "
},
{
	"uri": "//localhost:1313/00_introduction/01_workshop_overview.html",
	"title": "Workshop Overview",
	"tags": [],
	"description": "",
	"content": "In this workshop, you will learn how image scanning can provide the security insights you need without affecting the level of flexibility you desire.\nIn particular, we\u0026rsquo;ll guide you on how to implement ECS Fargate image scanning with Sysdig Secure. The resulting solution will automatically scan any container image instance that is executed, and will warn you with reports about any vulnerabilities or misconfigurations in your workload. It will do this without leaving your AWS workflow, and without data leaving your AWS infrastructure.\n"
},
{
	"uri": "//localhost:1313/00_introduction/02_security_basics.html",
	"title": "Security basics",
	"tags": [],
	"description": "",
	"content": "It is extremely important to maintain a high level of security in your entire application environment. Not doing so can result in your system being compromised. This can incur significant costs and can lead to commercial \u0026amp; business issues, and failed compliance tests leading to a loss of trust with customers and monetary fines and/or settlement fees.\nIn a cloud native environment, the security of your application is dependent largely upon the security of your containers, but not exclusively - it also depends upon the infrastructure upon which it runs.\n"
},
{
	"uri": "//localhost:1313/00_introduction/03_image_scanning.html",
	"title": "Image Scanning",
	"tags": [],
	"description": "",
	"content": "Sysdig\u0026rsquo;s ImageVision provides a comprehensive suite of tools to enhance security across your application\u0026rsquo;s ecosystem. One critical part of this is scanning the images in your registry.\nAn image scanner inspects a container\u0026rsquo;s content to detect threats such as unencrypted passwords, known vulnerabilities, exposed ports, etc. You can implement scanning best practices on several phases of your DevOps pipeline, blocking threats before they are deployed into production, and without adding extra overhead.\nSysdig Secure manages every aspect of the container scan. With Sysdig you can define image scanning policies to validate a container\u0026rsquo;s content against vulnerability databases, and search for misconfigurations like running as a privileged user, unnecessary open ports, or leaked credentials.\nNot only can you create multiple policies that determine what the scan is looking for, but also when to implement it. For example, in your CI/CD pipeline you may wish to use the test site https://sandbox.payment-engine.com/ during your automated QA tests, but when building containers for production this must be the live https://payment-engine.com. Or, you may wish to scan specifically for PSI or NIST compliance in a production site.\nFurther, you may wish to scan existing running containers for \u0026lsquo;zero day\u0026rsquo; vulnerabilities that have recently been detected.\nIn either case, the output of the scan will be sent back to Sysdig from where you can browse the results or run reports.\nAlthough containers may be ingested into another system in order to be scanned, for example a Sysdig Secure backend, it\u0026rsquo;s considered best practice to scan the image \u0026lsquo;inline\u0026rsquo;, i.e. locally in its current location.\nWith inline scanning the contents of your containers will never leave your infrastructure. This protects your privacy and prevents credentials for repositories from leaking. It may also be a requirement when security concerns require an air-gapped environment.\nFurther, from an architectural standpoint, it is more scalable to have images scanned at the edge rather than sent to a central location.\n"
},
{
	"uri": "//localhost:1313/00_introduction/04_infra_runtime_sec.html",
	"title": "Infrastructure Runtime Security",
	"tags": [],
	"description": "",
	"content": "In the same way image scanning gives you visibility of vulnerabilities and threats pertaining specifically to an application\u0026rsquo;s containers, infrastructure scanning gives visibility of potential issues emanating from the environment on which these containers run.\nAWS provides a rich environment upon which to base your application, but it\u0026rsquo;s not without its risks. There are many places where bad actors can create harm, for example exposing data by making S3 buckets public, deleting bucket encryption, disabling MFA for an account, adding/removing IAM policies.\nFalco is an open source threat detection language that is widely used to detect and alert on runtime abnormalities. This tool can also be used to detect changes within the AWS environment.\n"
},
{
	"uri": "//localhost:1313/00_introduction/05_fargate_ecs_sec.html",
	"title": "AWS Fargate and ECS Security",
	"tags": [],
	"description": "",
	"content": "AWS Fargate and ECS allow you to deploy containerized workloads quickly. Those services are so convenient that many people leave them unattended, risking exposure to vulnerabilities inside their containers that can exfiltrate secrets, compromise business data, impact performance, and increase their AWS costs.\nFor example, think of some credentials mistakenly included in an image, later deployed on Fargate. They will be exposed to anyone with access to the image (think on the repository), or to the Fargate service.\nConsider a known vulnerability. Imagine you deploy a Fargate task to manage your API, and that it uses an old HTTP library version that ignores the setting to limit a request size. That could be catastrophic! Say you expect requests no bigger than 1MB, but a malicious actor exploits this vulnerability to send requests as big as 80GB. This will absolutely take a toll in your AWS bill, and might cause your service to throttle.\nThose are serious threats.\nYou might be reluctant to implement further security checks, thinking they will take away the same flexibility you were looking for when you decided to use Fargate on ECS.\n"
},
{
	"uri": "//localhost:1313/00_introduction.html",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": " Learning Objectives Today we are going to learn the following topics:\n Workshop Overview   Security basics   Image Scanning   Infrastructure Runtime Security   AWS Fargate and ECS Security   "
},
{
	"uri": "//localhost:1313/10_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": " Prerequisites There are a few prerequisite tasks you must perform before getting started on this workshop. These are:\n Sign-up for a Sysdig Trial account   Start the Workshop...   At an AWS Event...   ...or on your own   We will step through each of these in turn.\n"
},
{
	"uri": "//localhost:1313/10_prerequisites/11_sysdig.html",
	"title": "Sign-up for a Sysdig Trial account",
	"tags": [],
	"description": "",
	"content": "You need a Sysdig Secure account and the associated API token\n Sign-up for a free Sysdig trial here https://sysdig.com/company/free-trial/\n You will receive a confirmation email with a link Once registered, log in and click your initials on the left nav bar, click \u0026lsquo;Settings\u0026rsquo; and navigate to \u0026lsquo;User Profile\u0026rsquo; and make a note of your \u0026lsquo;Sysdig Secure API Token\u0026rsquo;.  "
},
{
	"uri": "//localhost:1313/10_prerequisites/12_start_workshop.html",
	"title": "Start the Workshop...",
	"tags": [],
	"description": "",
	"content": " Getting Started To start the workshop, follow one of the following depending on whether you are\u0026hellip;\n \u0026hellip;attending an AWS hosted event, or \u0026hellip;running the workshop on your own  Once you have completed with either setup, continue with Install the required tools\n"
},
{
	"uri": "//localhost:1313/10_prerequisites/13_aws_event.html",
	"title": "At an AWS Event...",
	"tags": [],
	"description": "",
	"content": " To complete this workshop, you are provided with an AWS account via the AWS Event Engine service. A team hash will be provided to you by event staff.\nIf you are currently logged in to an AWS Account, you can logout using this link\n Create AWS Account 1 . Connect to the portal by clicking the button or browsing to https://dashboard.eventengine.run/. The following screen shows up. Enter the provided hash in the text box. The button on the bottom right corner changes to Accept Terms \u0026amp; Login. Click on that button to continue.\nLeave the Event Engine tab open (A new tab will be used for the next step)\n 2 . Choose AWS Console, then Open AWS Console.\n3 . Use a single region for the duration of this workshop. This workshop supports the following regions:\n us-east-1 (US East - N.Virginia)  Please select US East (N.Virginia) in the top right corner.\nThis account will expire at the end of the workshop and the all the resources created will be automatically deprovision-ed. You will not be able to access this account after today.\n Next step Once you have completed the step above, you can leave the AWS console open. You can now move to the First Module section.\n"
},
{
	"uri": "//localhost:1313/10_prerequisites/14_self_paced.html",
	"title": "...or on your own",
	"tags": [],
	"description": "",
	"content": " Running the workshop on your own Only complete this section if you are running the workshop on your own. If you are at an AWS hosted event (such as re:Invent, Kubecon, Immersion Day, etc), go to Start the workshop at an AWS event.\n  Create an AWS account   "
},
{
	"uri": "//localhost:1313/20_workshop_setup/20_cloud9.html",
	"title": "Cloud9",
	"tags": [],
	"description": "",
	"content": " AWS Cloud9 is a cloud-based integrated development environment (IDE) that Let’s you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don’t need to install files or configure your development machine to start new projects.\nAdd a new Cloud9 IDE environment 1 . Within the AWS console, use the region drop list to select us-east-1 (N. Virginia). This will ensure the workshop script provisions the resources in this same region..\n2 . Navigate to the cloud9 console or just search for it under the AWS console services menu.\n3 . Click the Create environment button\n4 . For the name use sysdig-workshop\n5 . Select Other instance type and choose t3.medium\n6 . Leave all the other settings as default\nThis will take about 1-2 minutes to provision\n Configure Cloud9 IDE environment When the environment comes up, customize the environment by:\n1 . Close the welcome page tab\n2 . Close the lower work area tab\n3 . Open a new terminal tab in the main work area.\nYour workspace should now look like this and can hide the left hand environment explorer by clicking on the left side environment tab.\nIf you don\u0026rsquo;t like this dark theme, you can change it from the View / Themes Cloud9 workspace menu.\n Cloud9 requires third-party-cookies. You can whitelist the specific domains. You are having issues with this, Ad blockers, javascript disablers, and tracking blockers should be disabled for the cloud9 domain, or connecting to the workspace might be impacted.\n "
},
{
	"uri": "//localhost:1313/20_workshop_setup.html",
	"title": "Workshop Setup",
	"tags": [],
	"description": "",
	"content": " Workshop Setup There are some steps to prepare the environment for this workshop.\nObjectives of this section  AWS console Launch Cloud9 IDE Environment Deploy CloudTrail CloudFormation Template  TRAINING NOTE: Need to update all screenshots in this section\n"
},
{
	"uri": "//localhost:1313/20_workshop_setup/21_iamrole.html",
	"title": "Create an IAM role for your workspace",
	"tags": [],
	"description": "",
	"content": " Starting from here, when you see command to be entered such as below, you will enter these commands into Cloud9 IDE. You can use the Copy to clipboard feature (right hand upper corner) to simply copy and paste into Cloud9. In order to paste, you can use Ctrl + V for Windows or Command + V for Mac.\n  Follow this deep link to create an IAM role with Administrator access. Confirm that AWS service and EC2 are selected, then click Next to view permissions. Confirm that AdministratorAccess is checked, then click Next to review. Enter Sysdig-Workshop-Admin for the Name, and select Create Role   "
},
{
	"uri": "//localhost:1313/20_workshop_setup/22_workspaceiam.html",
	"title": "Attach the IAM role to your Workspace",
	"tags": [],
	"description": "",
	"content": " Follow this deep link to find your Cloud9 EC2 instance Select the instance, then choose Actions / Instance Settings / Attach/Replace IAM Role  Choose Sysdig-Workshop-Admin from the IAM Role drop down, and select Apply  "
},
{
	"uri": "//localhost:1313/20_workshop_setup/23_cloud.html",
	"title": "Update IAM settings for your Workspace",
	"tags": [],
	"description": "",
	"content": " Cloud9 normally manages IAM credentials dynamically. This isn\u0026rsquo;t currently compatible with the EKS IAM authentication, so we will disable it and rely on the IAM role instead.\n  Return to your workspace and click the gear icon (in top right corner), or click to open a new tab and choose \u0026ldquo;Open Preferences\u0026rdquo; Select AWS SETTINGS Turn off AWS managed temporary credentials Close the Preferences tab   Let\u0026rsquo;s run the command below, the following actions will take place as we do that:\n🔹 Install jq- jq is a command-line tool for parsing JSON\n🔹 Ensure temporary credentials aren’t already in place.\n🔹 Remove any existing credentials file.\n🔹 Set the region to work with our desired region.\n🔹 Validate that our IAM role is valid.\nsudo yum -y install jq rm -vf ${HOME}/.aws/credentials export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account) export AWS_REGION=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r '.region') test -n \u0026quot;$AWS_REGION\u0026quot; \u0026amp;\u0026amp; echo AWS_REGION is \u0026quot;$AWS_REGION\u0026quot; || echo AWS_REGION is not set echo \u0026quot;export ACCOUNT_ID=${ACCOUNT_ID}\u0026quot; | tee -a ~/.bash_profile echo \u0026quot;export AWS_REGION=${AWS_REGION}\u0026quot; | tee -a ~/.bash_profile aws configure set default.region ${AWS_REGION} aws configure get default.region aws sts get-caller-identity --query Arn | grep Sysdig-Workshop-Admin -q \u0026amp;\u0026amp; echo \u0026quot;IAM role valid\u0026quot; || echo \u0026quot;IAM role NOT valid\u0026quot; curl -s https://gist.githubusercontent.com/johnfitzpatrick/d55097212d9bb4e1442383a5e3339b01/raw/90aa0dbb5b7e35277aea87fad12879e987f4c820/deploy-amazon-ecs-sample.sh \u0026gt; deploy-amazon-ecs-sample.sh chmod +x deploy-amazon-ecs-sample.sh  If the IAM role is not valid, DO NOT PROCEED. Go back and confirm the steps on this page.\n"
},
{
	"uri": "//localhost:1313/20_workshop_setup/24_setup_cloudtrail.html",
	"title": "Setup CloudTrail Runtime Security",
	"tags": [],
	"description": "",
	"content": "We will be looking at CloudTrail runtime security in module 3 of this workshop. However, the CloudFormation template required can take up to ten minutes to deploy. So, we will start the deployment now, and it should be complete later when we need it.\nThere are two steps required to enable CloudTrail runtime security:\n Firstly, you must enable AWS Security Hub in the account, then Deploy the Sysdig CloudConnector CloudFormation template.   "
},
{
	"uri": "//localhost:1313/20_workshop_setup/24_setup_cloudtrail.html",
	"title": "Setup CloudTrail Runtime Security",
	"tags": [],
	"description": "",
	"content": "We will be looking at CloudTrail runtime security in module 3 of this workshop. However, the CloudFormation template required can take up to ten minutes to deploy. So, we will start the deployment now, and it should be complete later when we need it.\nThere are two steps required to enable CloudTrail runtime security. Firstl, you must enable AWS Security Hub in the account, then you will deploy the Sysdig CloudConnector CloudFormation template.\n Enable AWS Security Hub   Installing the CloudConnector   "
},
{
	"uri": "//localhost:1313/25_setup_cloudtrail_integration.html",
	"title": "Module 3 Prework: Setup CloudTrail Runtime Security",
	"tags": [],
	"description": "",
	"content": " Module 3 Prework: Setup CloudTrail Runtime Security We will be looking at CloudTrail runtime security in module 3 of this workshop. However, the CloudFormation template required can take up to ten minutes to deploy. So, we will start the deployment now, and it should be complete later when we need it.\nThere are two steps required to enable CloudTrail runtime security:\n Firstly, you must enable AWS Security Hub in the account, then Deploy the Sysdig CloudConnector CloudFormation template.  "
},
{
	"uri": "//localhost:1313/30_module_1.html",
	"title": "Module 1: Amazon ECR Image Scanning",
	"tags": [],
	"description": "",
	"content": " Module 1: Amazon ECR Image Scanning Overview Amazon Elastic Container Registry (ECR) is a fully-managed Docker container registry that makes it easy for developers to store, manage, and deploy Docker container images. It hosts your container images in a highly available and scalable architecture, allowing you to reliably deploy containers for your applications. Sysdig provides inline scanning of your Amazon ECR registry as part of Sysdig\u0026rsquo;s ImageVision.\nIn this lab we will:\nTRAINING NOTE: Remove this list and just keep the interactive one once that all is build\n Setup the Amazon ECR Registry Deploy the Amazon ECR Integration Push and scan an image from the registry See scan results on Sysdig Secure dashboard Download Example Dockerfile and Sources Modify the image and trigger a second scan   Setup Amazon ECR Registry   Deploy the Amazon ECR Integration   Push and Scan an Image from the Registry   Modify the image and trigger a second scan   Reference Architecture Enabling Amazon ECR Image Scanning is as simple as deploying a single CloudFormation template, and once deployed, all images that are pushed to the registry will be automatically scanned within your AWS account.\nHow this is implemented is illustrated below.\nOnce a new image is pushed to Amazon ECR, this is picked up by Amazon EventBridge and passed to a Lambda function which creates an ephemeral CodeBuild task to build and scan the base image. The results of the scan are then sent to the Sysdig Secure backend. You are not required to configure, or expose, the registry on the Sysdig Secure side. Also, the image itself is not sent to Sysdig, but only the image metadata.\nAn important point to note is that, although the scan actually happens with this AWS pipeline, you maintain the scanning policies and results with Sysdig.\n"
},
{
	"uri": "//localhost:1313/30_module_1/30_setup_ecr.html",
	"title": "Setup Amazon ECR Registry",
	"tags": [],
	"description": "",
	"content": " For the purposes of this lab you need to create an Amazon ECR registry. To do this, follow the steps below\n Log into your Cloud9 Workspace\n Run the following commands, naming it as appropriate\n  aws ecr create-repository --repository-name aws-workshop --image-scanning-configuration scanOnPush=true  The output will be as follows\n{ \u0026quot;repository\u0026quot;: { \u0026quot;repositoryArn\u0026quot;: \u0026quot;arn:aws:ecr:us-east-1:845151661675:repository/aws-workshop\u0026quot;, \u0026quot;registryId\u0026quot;: \u0026quot;845151661675\u0026quot;, \u0026quot;repositoryName\u0026quot;: \u0026quot;aws-workshop\u0026quot;, \u0026quot;repositoryUri\u0026quot;: \u0026quot;845151661675.dkr.ecr.us-east-1.amazonaws.com/aws-workshop\u0026quot;, \u0026quot;createdAt\u0026quot;: 1602848100.0, \u0026quot;imageTagMutability\u0026quot;: \u0026quot;MUTABLE\u0026quot;, \u0026quot;imageScanningConfiguration\u0026quot;: { \u0026quot;scanOnPush\u0026quot;: true }, \u0026quot;encryptionConfiguration\u0026quot;: { \u0026quot;encryptionType\u0026quot;: \u0026quot;AES256\u0026quot; } } }  Set up Credentials in Command line Docker Shortly you will use your Cloud9 Workspace to create and push a docker container to your new ECR Repository, however, before doing so you must configure docker\u0026rsquo;s access to the repository.\n Log into your Cloud9 workspace\n Authenticate the Docker command line tool to this Amazon ECR registry, using AWS CLI tool as follows\n  export ECR_NAME=aws-workshop export REGION=us-east-1 export AWS_ACCOUNT=$(aws sts get-caller-identity | jq '.Account' | xargs) echo \u0026quot;$ECR_NAME, $REGION, $AWS_ACCOUNT\u0026quot; aws ecr get-login-password --region $REGION | \\ docker login --username AWS --password-stdin \\ $AWS_ACCOUNT.dkr.ecr.$REGION.amazonaws.com   ```bash export AWS_ACCOUNT=$(aws sts get-caller-identity | grep \"UserId\" | sed 's/^[^\"]*\"\\([^\"]*\\)\".*\"\\([^\"]*\\)\".*/\\2/') ``` -- The output should look similar to the following\nWARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded  Note For more details on this procedure, please refer to Amazon ECR registries - Amazon ECR\n"
},
{
	"uri": "//localhost:1313/30_module_1/31_deploy_ecr_integration.html",
	"title": "Deploy the Amazon ECR Integration",
	"tags": [],
	"description": "",
	"content": "This integration enables the Amazon Elastic Container Registry (ECR) to automatically trigger an action to scan every new container that is pushed into the registry.\n Log into your AWS Console and select \u0026lsquo;US East (N. Virginia) us-east-1\u0026rsquo; from the \u0026lsquo;Select a Region\u0026rsquo; dropdown on the top right. For the purposes of this exercise we will be using AWS Region us-east-1\n Navigate to this CloudFormation template.  Click Next.  For \u0026lsquo;ScanningType\u0026rsquo; make sure the default value of \u0026lsquo;Inline\u0026rsquo; is selected\n For \u0026lsquo;SysdigSecureEndpoint\u0026rsquo;, enter your \u0026lsquo;Sysdig Secure API Token\u0026rsquo; for the Sysdig Secure account you created earlier. You can find in your User Profile.  Click \u0026lsquo;Next\u0026rsquo;. You will be presented with \u0026lsquo;Configure stack options\u0026rsquo; page.\n Click \u0026lsquo;Next\u0026rsquo; accepting the default configuration options.  Make sure you tick the box acknowledging that AWS CloudFormation might create IAM resources with custom names.\n Click \u0026lsquo;Create stack\u0026rsquo;. You can view the status of the deployment from the Amazon CloudFormation screen.   This deployment will create a new Amazon CloudBuild project to automatically scan container images pushed to ECR registries.\nTo view your Amazon CloudBuild projects, browse to https://console.aws.amazon.com/codesuite/codebuild/projects?region=us-east-1\nTRAINING NOTE: New ScreenShot Below!!!\n"
},
{
	"uri": "//localhost:1313/30_module_1/32_image_from_registry.html",
	"title": "Push and Scan an Image from the Registry",
	"tags": [],
	"description": "",
	"content": " Download Example Dockerfile and Sources To illustrate the images scanning we will build an example Node.JS application based on the official “hello world” example described in their website.\n Go to your Cloud9 Workspace and download and uncompress example container files\nwget https://github.com/sysdiglabs/hello-world-node-vulnerable/releases/download/v1.0/hello-world-node-vulnerable.zip unzip hello-world-node-vulnerable.zip cd hello-world-node-vulnerable/  And build and push the image to ECR\nexport IMAGE=$AWS_ACCOUNT.dkr.ecr.$REGION.amazonaws.com/$ECR_NAME docker build . -t $IMAGE docker push $IMAGE  Check that an image scan is automatically triggered  Once complete you will see that this image has some issues  As soon as the image finishes being pushed to the registry, a new Amazon CodeBuild pipeline will be automatically created that executes an image scan.\nIf you wish, you can check the CodeBuild pipeline status by visiting: https://console.aws.amazon.com/codesuite/codebuild/projects TRAINING NOTE: New ScreenShot Above and Below!!!\n  Click on “InlineSecure Scanning” build project. See Scan Results on Sysdig Secure Dashboard TRAINING NOTE: Instructions here on how to get to scan results and search the image\nAs you can see, the image have several major vulnerabilities.\nTRAINING NOTE: Explanation of the benefits of a single source of truth, and some Sysdig marketing stuff: policies, stopping gates, misconfigurations\n"
},
{
	"uri": "//localhost:1313/30_module_1/33_image_rescan.html",
	"title": "Modify the image and trigger a second scan",
	"tags": [],
	"description": "",
	"content": "For illustration purposes, let\u0026rsquo;s rebuild our image and make it more secure by starting with a different Base image. To do so:\n Go back into Cloud9 Workspace Edit the Dockerfile and in the first line update the base image from\nFROM node:12  to\nFROM bitnami/node:12`  The file should look like this\nFROM bitnami/node:12 # Create app directory WORKDIR /usr/src/app # Install app dependencies # A wildcard is used to ensure both package.json AND package-lock.json are copied # where available (npm@5+) COPY package*.json ./ RUN npm install # If you are building your code for production # RUN npm ci --only=production # Bundle app source COPY . . EXPOSE 8080 CMD [ \u0026quot;node\u0026quot;, \u0026quot;server.js\u0026quot; ]  Now rebuild and push the image again with:\ndocker build . -t $IMAGE docker push $IMAGE  The image will automatically be scanned, as before.\n Once completed, you will see that the scan result now shows it doesn’t have any vulnerabilities.   TRAINING NOTE: New ScreenShot Above!!!\n"
},
{
	"uri": "//localhost:1313/40_module_2/40_install_amazon_ecs_cli.html",
	"title": "Install Amazon ECS CLI",
	"tags": [],
	"description": "",
	"content": "We will use the Amazon ECS CLI tool to deploy an example ECS cluster, so we\u0026rsquo;ll need to install it on our Cloud9 Workspace. To install Amazon ECS CLI, follow the steps below\n Log into your Cloud9 Workspace\n Download the Amazon ECS CLI binary and make it executable .\nsudo curl -Lo /usr/local/bin/ecs-cli https://amazon-ecs-cli.s3.amazonaws.com/ecs-cli-linux-amd64-latest sudo chmod +x /usr/local/bin/ecs-cli  Check installation\necs-cli --version  Now create a file named task-execution-assume-role.json for our IAM role as follows\ncat \u0026lt;\u0026lt;- 'EOF' \u0026gt; \u0026quot;task-execution-assume-role.json\u0026quot; { \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Sid\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Principal\u0026quot;: { \u0026quot;Service\u0026quot;: \u0026quot;ecs-tasks.amazonaws.com\u0026quot; }, \u0026quot;Action\u0026quot;: \u0026quot;sts:AssumeRole\u0026quot; } ] } EOF  Create task execution role and attach the task execution role policy:\naws iam --region us-east-1 create-role --role-name ecsTaskExecutionRole --assume-role-policy-document file://task-execution-assume-role.json aws iam --region us-east-1 attach-role-policy --role-name ecsTaskExecutionRole --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy   "
},
{
	"uri": "//localhost:1313/40_module_2.html",
	"title": "Module 2: Fargate automatic image scanning",
	"tags": [],
	"description": "",
	"content": " Module 2: Fargate automatic image scanning Module Overview Amazon Fargate is a serverless compute engine for containers that works with both Amazon Elastic Container Service (ECS) and Amazon Elastic Kubernetes Service (EKS). It allocates the correct amount of compute resources, eliminating the need to choose instance types and scaling cluster capacity. With Fargate, you pay for the minimum resources required to run your containers. Sysdig provides the ability to scan running Fargate services for known issues, in a similar manner to how it scans Amazon ECR.\nIn this lab we will\n Install Amazon ECS CLI Deploy Sysdig Secure automatic image scanner for Fargate Deploy an ECS cluster using Fargate See that CodeBuild pipelines are automatically created to scan them See scan results on Sysdig Secure dashboard  Reference Architecture Any deploy command directed at ECS Fargate will trigger an image scanning event. In particular the deploy command is detected by Amazon EventBridge, which will trigger a CodeBuild pipeline via an AWS Lambda function. It is within this CodeBuild pipeline that the image scanning runs. This is very similar workflow to how we seen earlier with Amazon ECR scanning.\nThe Sysdig inline image scanner will inspect the image to be deployed and will send its metadata to the Sysdig backend. The actual image contents won\u0026rsquo;t leave the CodeBuild pipeline.\nThe Sysdig backend then evaluates the container metadata against your security policies. It will generate a scan report if the image doesn\u0026rsquo;t pass your security requirements, so you can take action.\n"
},
{
	"uri": "//localhost:1313/40_module_2/41_deploy_image_scanner_for_fargate.html",
	"title": "Deploy Sysdig Secure Automatic Image Scanner for Fargate",
	"tags": [],
	"description": "",
	"content": "To deploy the Sysdig image scanner for Fargate, we\u0026rsquo;ll again use Amazon CloudFormation. The procedure is identical to how we installed Amazon ECR Integration in the previous lab, so this time we\u0026rsquo;ll use the AWS CLI instead.\nNote You can find instructions on using the CLI on the Sysdig Fargate scanning installation page\n First we\u0026rsquo;ll set a couple of environment parameters to simplify the actual aws command,\nAPIToken=\u0026quot;F4k3F4k3-F4k3-F4k3-F4k3-F4k3F4k3F4k3\u0026quot; CFURI=\u0026quot;https://cf-templates-secure-scanning-ecs.s3.amazonaws.com/ecs-image-scanning.template\u0026quot;  Then run the the following AWS CloudFormation command (which uses those environment parameters)\naws cloudformation create-stack \\ --stack-name ECSImageScanning \\ --template-body $CFURI \\ --parameters ParameterKey=ECSInlineSecureAPIToken,ParameterValue=$APIToken ParameterKey=ECSInlineScanningType,ParameterValue=Inline \\ --capabilities \u0026quot;CAPABILITY_NAMED_IAM\u0026quot;  You can check the status of the CloudFormation task by browsing to the CloudFormation UI.\n  Wait until the CloudFormation task completes, which may take several minutes.\nOnce all stacks are created, you will be ready to deploy our ECS tasks in a Fargate cluster securely, as all images will be scanned automatically. In the next steps we will see this scanning as it happens.\n"
},
{
	"uri": "//localhost:1313/40_module_2/42_deploy_an_ecs_cluster.html",
	"title": "Deploy an ECS cluster using Fargate",
	"tags": [],
	"description": "",
	"content": "To illustrate the automatic scanning, we will now deploy a sample ECS cluster that scales using Fargate\n Create a cluster configuration and create a cluster\necs-cli configure --cluster tutorial --default-launch-type FARGATE --config-name tutorial --region us-east-1 ecs-cli up --cluster-config tutorial --ecs-profile tutorial-profile  The output should show a VPC and two Subnets have been created:-\nINFO[0000] Created cluster cluster=tutorial region=us-east-1 INFO[0000] Waiting for your cluster resources to be created... INFO[0000] Cloudformation stack status stackStatus=CREATE_IN_PROGRESS INFO[0060] Cloudformation stack status stackStatus=CREATE_IN_PROGRESS VPC created: vpc-046ed77edcd796e19 Subnet created: subnet-045df8f58a51b2291 Subnet created: subnet-0e4623283c4907ea7 Cluster creation succeeded.  Set the names of the VPC and Subnets as an environment variables, as follows\nexport VPC=vpc-046ed77edcd796e19 export SUBNET1=subnet-045df8f58a51b2291 export SUBNET2=subnet-0e4623283c4907ea7  Note You can subsequently get these details from the CloudFormation UI\n   Run the following command to retrieve the id of the default security group and allow inbound access on port 80\nexport group_id=$(aws ec2 describe-security-groups --filters Name=vpc-id,Values=$VPC --region us-east-1 | jq '.SecurityGroups[0].GroupId' | xargs) aws ec2 authorize-security-group-ingress --group-id $group_id --protocol tcp --port 80 --cidr 0.0.0.0/0 --region us-east-1 echo The security group ID is $group_id  Create ecs-params.yml file as follows, replacing subnets and security group id.\ncat \u0026lt;\u0026lt;- 'EOF' \u0026gt; \u0026quot;ecs-params.yml\u0026quot; version: 1 task_definition: task_execution_role: ecsTaskExecutionRole ecs_network_mode: awsvpc task_size: mem_limit: 0.5GB cpu_limit: 256 run_params: network_configuration: awsvpc_configuration: subnets: - \u0026quot;subnet-045df8f58a51b2291\u0026quot; - \u0026quot;subnet-0e4623283c4907ea7\u0026quot; security_groups: - \u0026quot;sg-07c8bf61105e07021\u0026quot; assign_public_ip: ENABLED EOF  Create docker-compose.yaml file as follows\ncat \u0026lt;\u0026lt;- 'EOF' \u0026gt; \u0026quot;docker-compose.yml\u0026quot; version: '3' services: web: image: amazon/amazon-ecs-sample ports: - \u0026quot;80:80\u0026quot; logging: driver: awslogs options: awslogs-group: tutorial awslogs-region: us-east-1 awslogs-stream-prefix: web EOF  Deploy to the cluster:\necs-cli compose --project-name tutorial service up --create-log-groups --cluster-config tutorial --ecs-profile tutorial-profile   TRAINING NOTE: ALTERNATIVE FLOW::Above steps are error prone. Maybe replace steps 1-5 above with a script (maybe pull it in from a guthub, or gist during Cloud9 Workspace setup?\nWe\u0026rsquo;ll use a custom deployment script that will\n Retrieve the id of the default security group for the VPC creates, and allows inbound access on port 80\n Create a ecs-params.yml file using the subnets and security group already retrieved\n Create a docker-compose.yaml to instantiate the image amazon/amazon-ecs-sample\n   First set the names of the VPC and Subnets as an environment variables, as follows\nexport VPC=vpc-046ed77edcd796e19 export SUBNET1=subnet-045df8f58a51b2291 export SUBNET2=subnet-0e4623283c4907ea7  Retrieve and view the deployment script\ncurl -s https://gist.githubusercontent.com/johnfitzpatrick/d55097212d9bb4e1442383a5e3339b01/raw/90aa0dbb5b7e35277aea87fad12879e987f4c820/deploy-amazon-ecs-sample.sh \u0026gt; deploy-amazon-ecs-sample.sh chmod +x deploy-amazon-ecs-sample.sh cat -n deploy-amazon-ecs-sample.sh  Now run the script\n./deploy-amazon-ecs-sample.sh  Once completed you can see on the Amazon ECS UI\n  "
},
{
	"uri": "//localhost:1313/40_module_2/43_initiate_scan.html",
	"title": "Initiate CodeBuild Pipelines Build and Scan",
	"tags": [],
	"description": "",
	"content": " Now go to CodeBuild \u0026gt; Build projects and see the task in progress.  TRAINING NOTE: Recheck the following steps \u0026amp; screens in live environment - need to fix Cloud9 issues first\n"
},
{
	"uri": "//localhost:1313/40_module_2/44_sysdig_secure_dashboard.html",
	"title": "View Results on Sysdig Secure Dashboard",
	"tags": [],
	"description": "",
	"content": "The beauty of the Amazon ECS Fargate with Sysdig is that you have a centralised location to report on your scanning results.\n Log into Sysdig Secure, and Browse to \u0026lsquo;Image Scanning \u0026gt; Scan Results\u0026rsquo;.\n You can drill into TRAINING NOTE: UPDATE INSTRUCTION WHEN GRABBING FINAL SCREENSHOT\n  "
},
{
	"uri": "//localhost:1313/50_module_3.html",
	"title": "Module 3: CloudTrail Runtime Security",
	"tags": [],
	"description": "",
	"content": " Module 3: CloudTrail Runtime Security Module Overview Every action taken over your infrastructure resources results in a registry in AWS CloudTrail. This includes all AWS account activity, actions taken through the AWS Management Console, AWS SDKs, command line tools, and other AWS services. This event history is useful for detecting unwanted or unexpected activity involving your AWS resources, however as your infrastructure grows, the amount of events and operational trails can become so huge that analyzing them is no longer practical. However, failing to react to a threat quickly could potentially have major consequences.\nIn this module we will explain how to audit AWS CloudTrail events with Sysdig Cloud Connector. Once deployed in your infrastructure, the Sysdig Cloud Connector analyzes every CloudTrail entry in real time, and provides AWS threat detection by evaluating each event against a flexible set of security rules based on Falco. This allows you to detect threats and raise notifications so you can address security threats as quickly as possible.\nReference Architecture Similar to ECS Fargate serverless, incoming CloudTrail events are fetched and stored in an S3 bucket. A subscription in the SNS topic will then forward the events to the Sysdig Cloud Connector endpoint. The Cloud Connector will then analyze each event against a configured set of Falco rules.\nSysdig Cloud Connector provides several notification options, including sending security findings to Sysdig Backend, as well as AWS Security Hub and AWS CloudWatch, so you can review the security events without leaving your AWS console.\nA set of out-of-the-box Falco rules for CloudTrail is available in the Sysdig Cloud Connector, saving you a lot of time getting started, but you can complement these with your own custom rules to detect any cloud command.\nThe included out-of-the-box CloudTrail rules can detect events like:\n Add an AWS user to a group. Allocate a New Elastic IP Address to AWS Account. Attach an Administrator Policy. Create an AWS user. Deactivate MFA for user access. Delete bucket encryption.  These rules are also mapped against NIST 800-190 security standard controls. More compliance mapping for additional security standards like PCI or CIS will be provided in the future\n"
},
{
	"uri": "//localhost:1313/50_module_3/51_setup_cloudtrail_runtime_security.html",
	"title": "Setup CloudTrail Runtime Security",
	"tags": [],
	"description": "",
	"content": "If you followed this workshop from the beginning then you should have deployed the CloudTrail CloudFormation Template earlier. If you didn\u0026rsquo;t, then go back and complete this step now Setup CloudTrail Runtime Security, however please note that this can take up to ten minutes to complete.\nTo check it has been deployed successfully, navigate to https://console.aws.amazon.com/cloudformation/ and search for CloudConnector. You should see it\u0026rsquo;s status is CREATE_COMPLETE.\n"
},
{
	"uri": "//localhost:1313/50_module_3/52_detecting_runtime_cloud_security_threats.html",
	"title": "Detecting Runtime Cloud Security Threats",
	"tags": [],
	"description": "",
	"content": "Let\u0026rsquo;s look at an example of AWS threat detection in action with CloudTrail and the Sysdig Cloud Connector. To do so we\u0026rsquo;ll create an S3 bucket, and make it public\n Log into Cloud9 Workspace Create an S3 bucket. S3 bucketnames are globally unique, so you use your initials combined with a timestamp\nINITIALS=\u0026lt;your initial\u0026gt; BUCKETNAME=$INITIALS-$(date +%s) aws s3api create-bucket --bucket $BUCKETNAME --acl public-read  Now delete the S3 bucket\u0026rsquo;s encryption. This should be considered a potential security threat.\naws s3api delete-bucket-encryption --bucket $BUCKETNAME  To view details of this event, browse to CloudTrail then \u0026lsquo;Event History\u0026rsquo;\nDev Note Add screenshot here\n Click the event just created\nIf you scroll down you\u0026rsquo;ll see details of the new CloudTrail event that was created. It looks like this in JSON format:\n{ \u0026quot;eventVersion\u0026quot;: \u0026quot;1.05\u0026quot;, \u0026quot;userIdentity\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;Root\u0026quot;, \u0026quot;principalId\u0026quot;: \u0026quot;999999999999\u0026quot;, \u0026quot;arn\u0026quot;: \u0026quot;arn:aws:iam::972909301756:root\u0026quot;, \u0026quot;accountId\u0026quot;: \u0026quot;999999999999\u0026quot;, \u0026quot;accessKeyId\u0026quot;: \u0026quot;FE1D489888F66424BBE7\u0026quot;, \u0026quot;sessionContext\u0026quot;: { \u0026quot;sessionIssuer\u0026quot;: {}, \u0026quot;webIdFederationData\u0026quot;: {}, \u0026quot;attributes\u0026quot;: { \u0026quot;mfaAuthenticated\u0026quot;: \u0026quot;true\u0026quot;, \u0026quot;creationDate\u0026quot;: \u0026quot;2020-06-18T07:52:40Z\u0026quot; } } }, \u0026quot;eventTime\u0026quot;: \u0026quot;2020-06-18T09:05:23Z\u0026quot;, \u0026quot;eventSource\u0026quot;: \u0026quot;iam.amazonaws.com\u0026quot;, \u0026quot;eventName\u0026quot;: \u0026quot;AttachUserPolicy\u0026quot;, \u0026quot;awsRegion\u0026quot;: \u0026quot;us-east-1\u0026quot;, \u0026quot;sourceIPAddress\u0026quot;: \u0026quot;37.132.12.63\u0026quot;, \u0026quot;userAgent\u0026quot;: \u0026quot;console.amazonaws.com\u0026quot;, \u0026quot;requestParameters\u0026quot;: { \u0026quot;userName\u0026quot;: \u0026quot;admin_test\u0026quot;, \u0026quot;policyArn\u0026quot;: \u0026quot;arn:aws:iam::aws:policy/AdministratorAccess\u0026quot; }, \u0026quot;responseElements\u0026quot;: null, \u0026quot;requestID\u0026quot;: \u0026quot;7fe1d489-550c-527f-6155-70d1522b95f0\u0026quot;, \u0026quot;eventID\u0026quot;: \u0026quot;dd9fe2aa-70d1-4bbf-2ac4-b4766642e73b\u0026quot;, \u0026quot;eventType\u0026quot;: \u0026quot;AwsApiCall\u0026quot;, \u0026quot;recipientAccountId\u0026quot;: \u0026quot;999999999999\u0026quot; }   All CloudTrail events have the following key fields:\n userIdentity: The user who sent the request. eventName: Specifies the type of event. requestParameters: Contains all of the parameters related to the request.  If a request has an errorCode field, it means that it could not be processed because of an error. For example, the requester may not have had permission to perform a change.\nIn this case, we can see how a policy has just been attached (AttachUserPolicy) to a user (admin_test) with administrator access (arn:aws:iam::aws:policy/AdministratorAccess).\nA Falco rule to detect this elevation of privileges would look like this:\n- rule: Delete bucket encryption desc: Detect deleting configuration to use encryption for bucket storage condition: jevt.value[/eventName]=\u0026quot;DeleteBucketEncryption\u0026quot; and not jevt.value[/errorCode] exists output: A encryption configuration for a bucket has been deleted (requesting user=%jevt.value[/userIdentity/arn], requesting IP=%jevt.value[/sourceIPAddress], AWS region=%jevt.value[/awsRegion], bucket=%jevt.value[/requestParameters/bucketName]) priority: CRITICAL tags: [cloud, source=cloudtrail, aws, NIST800_53, NIST800_53_AU8] source: k8s_audit  This particular rule is already included out-of-the-box in Sysdig Cloud Connector.\nThe jevt.value contains the JSON content of the event, and we are using it in the condition. Using the jsonpath format, we can indicate what parts of the event we want to evaluate.\nThe output will provide context information including the requester username and IP address - this is what will be sent through all of the enabled notification channels.\nAs you can see, this is a regular Falco rule. CloudTrail compatibility is achieved by handling its events as JSON objects, and referring to the event information using JSONPath.\n"
},
{
	"uri": "//localhost:1313/50_module_3/53_checking_security_findings_in_the_aws_security_hub.html",
	"title": "Checking Security Findings in AWS Security Hub",
	"tags": [],
	"description": "",
	"content": "You can check these events without leaving the AWS console. This is how findings reported by Sysdig Cloud Connector look in the AWS Security Hub:\n Browse to Security Hub and click \u0026lsquo;Findings\u0026rsquo; on the left.  The details of one of these findings provide all the information you need to take immediate action:\nAnd they appear in JSON format in AWS CloudWatch log streams:\n"
},
{
	"uri": "//localhost:1313/50_module_3/54_modifying_a_falco_rule_for_cloudtrail10module_2_fargate_automatic_image_scanning.html",
	"title": "Modifying a Falco Rule for CloudTrail",
	"tags": [],
	"description": "",
	"content": "Using Sysdig Cloud Connector, you are not limited to the out-of-the-box rules provided. You can modify existing rules, or write your own tailored to your own needs.\nLet’s try first modifying a rule. The following rule checks if a resource is created in a region that you are not usually using. But to be active, you have to specify which regions you want to detect.\n- list: disallowed_aws_regions items: [] - rule: AWS command executed on unused region desc: Detect AWS command execution on unused regions condition: not jevt.value[/errorCode] exists and jevt.value[/awsRegion] in (disallowed_aws_regions) output: An AWS command has been executed on an unused region (requesting user=%jevt.value[/userIdentity/arn], requesting IP=%jevt.value[/sourceIPAddress], AWS region=%jevt.value[/awsRegion] priority: CRITICAL tags: [cloud, source=cloudtrail, aws, NIST800_53, NIST800_53_AC-2(12)(b)] source: k8s_audit  [Include here instructions on how to download and update rules files when that mechanism is implemented]\n For the disallowed_aws_regions list, edit the items to include us-west-1 and us-west-2:\n-- list: disallowed_aws_regions items: [us-west-1, us-west-2]  DEV NOTE How do I escape \u0026lsquo;-\u0026rsquo; within ```? Parser renders it as a html list, so added \u0026lsquo;\u0026ndash;\u0026rsquo;\n[Instructions to update and reload rules]\n Now we create a new log group on us-west-2\naws logs create-log-group --log-group-name \u0026quot;test_unused_region\u0026quot; --region=\u0026quot;us-west-2\u0026quot;  CloudTrail takes up to 10 minutes to provide the events. When the event is available, Cloud Connector will trigger the rule and we will see a new security finding appear in AWS Security Hub.\n  [Introduce screenshots when rule update process is available]\n"
},
{
	"uri": "//localhost:1313/60_conclusions.html",
	"title": "Conclusions",
	"tags": [],
	"description": "",
	"content": " Conclusions  There are several key points on Sysdig\u0026rsquo;s approach to Amazon ECR and Amazon Fargate image scanning:\n There is no need to build specific pipelines for each image. The scan will be automatically triggered for any workload that is executed in ECS Fargate across your whole infrastructure, or uploaded to ECR.\n As the container metadata is retained in the Sysdig backend, there is no need to re-scan the images. Any update in the vulnerability databases, or any change in your policies, will eventually update the scan reports.\n The Sysdig backend will act as a single source of truth for the security posture of all your running workloads and container repositories. It centralizes all the security reports and from the same tool, you will also be able to check your compliance status and runtime security events.\n  Keep in mind that this approach is only part of the solution. You can further strengthen your security by implementing image scanning in other places of your DevOps lifecycle, like the CI/CD pipelines or in the registry. You should also implement other security controls like runtime security, compliance checks, or activity audit. Sysdig helps you extend security controls all over your AWS container services while serving as a single source of truth for the security posture of all your infrastructure.\nAWS security can save your infrastructure from failing at its worst moment. It will protect you and your customer data against misconfigurations, a security compromise, or your wallet from unexpected fees.\nCloudTrail is a great source of truth, as it can see everything that is happening in your AWS accounts. Leverage Sysdig Secure by deploying Sysdig Cloud Connector for CloudTrail and obtaining the runtime visibility you need to implement AWS threat detection. Its out-of-the-box set of Falco rules for CloudTrail minimizes the setup effort, response time, and resources needed for investigating security events.\n"
},
{
	"uri": "//localhost:1313/70_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Cleanup Module 3  Delete the log group created to test the Falco rule modification\naws logs delete-log-group --log-group-name \u0026quot;test_unused_region\u0026quot; --region=\u0026quot;us-west-2\u0026quot;  Delete an S3 bucket\naws s3api delete-bucket --bucket $BUCKETNAME   Module 2  Remove ECS Cluster\necs-cli compose service rm --cluster-config tutorial --ecs-profile tutorial-profile ecs-cli down --force --cluster-config tutorial --ecs-profile tutorial-profile  Remove Image Scanner Integration for Fargate\naws cloudformation delete-stack --stack-name ECSImageScanning  Unattach the task execution role policy \u0026amp; delete role:\naws iam --region us-east-1 detach-role-policy --role-name ecsTaskExecutionRole --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy aws iam --region us-east-1 delete-role --role-name ecsTaskExecutionRole   Module 1  Remove container image from Amazon ECR Registry\ndocker registry rmi $IMAGE  Remove Amazon ECR Integration\naws cloudformation delete-stack --stack-name ECSImageScanning  Remove Amazon ECR Registry\naws ecr delete-repository --repository-name aws-workshop --force   Introduction  Installing the CloudConnector CloudFormation Template\naws cloudformation delete-stack --stack-name CloudConnector  Disable Security Hub\naws securityhub disable-security-hub   "
},
{
	"uri": "//localhost:1313/20_workshop_setup/24_setup_cloudtrail/241_enable_aws_security_hub.html",
	"title": "Enable AWS Security Hub",
	"tags": [],
	"description": "",
	"content": "TRAINING NOTE: Security Hub isn\u0026rsquo;t a Sysdig thing, so in the interests of making things shorter, can we remove the individual steps/screenshots and replace them with this single command?\nTo enable AWS Security Hub:\n Log into your Cloud9 Workspace\n Run the following command\n  aws securityhub enable-security-hub --enable-default-standards  TRAINING NOTE: MAKE A GIF OF THIS STEPS!!! having all the pictures here adds little extra info but takes a lot of scrolling\n First make sure you are logged into your AWS account with your browser then browse to AWS Security Hub. The screen you\u0026rsquo;re presented with depends upon the status of your AWS account.\n If you see this “Get started with Security Hub” page below, then click \u0026lsquo;Go to Security Hub\u0026rsquo;.  Then, click \u0026lsquo;Enable Standard\u0026rsquo; in the dialog.  However, if you see the Summary web page (shown later here), you can skip to the Installing the CloudConnector.  In the \u0026ldquo;Welcome to AWS Security Hub\u0026rdquo; page, you can indicate which security standard controls you want to enable, or accept the default. Note These controls are part of the default AWS Security Hub mechanism, and they are not related to the detections that Sysdig Cloud Connector is going to find for you.\n Click \u0026lsquo;Enable Security Hub\u0026rsquo;. The \u0026ldquo;Summary\u0026rdquo; page for Security Hub will be shown.\n  You may see a temporary red warning about AWS Config not being appropriately enabled, but it will disappear on its own once the Security Hub detects that the activation has been made. It has no relation to the use of Sysdig Cloud Connector.  "
},
{
	"uri": "//localhost:1313/25_setup_cloudtrail_integration/241_enable_aws_security_hub.html",
	"title": "Installing the CloudConnector",
	"tags": [],
	"description": "",
	"content": " Step 1. Enable AWS Security Hub To enable AWS Security Hub:\n Log into your Cloud9 Workspace\n Run the following command\naws securityhub enable-security-hub --enable-default-standards  Log into your AWS account with your browser then browse to AWS Security Hub.\n   You may see a temporary red warning about AWS Config not being appropriately enabled, but it will disappear on its own once the Security Hub detects that the activation has been made. It has no relation to the use of Sysdig Cloud Connector.\n You may see a temporary red warning about AWS Config not being appropriately enabled, but it will disappear on its own once the Security Hub detects that the activation has been made. It has no relation to the use of Sysdig Cloud Connector.  -- Step 2. Install the CloudConnector To install this tool, we will be using a CloudFormation Template. Follow the steps below to install the Sysdig CloudConnector:\n Navigate to the CloudFormation template for Sysdig Cloud Connector deployment template. The template will preview in CloudFormation.  On the “Create stack” section, click the \u0026lsquo;Next\u0026rsquo; button to start setting up the template.  The “Specify stack details” section has no parameters for you to configure, so you can just press the Next button.  On _“Configure stack options_” screen, press the Next button. You can optionally add tag keys and values to the deployment, but no further configuration is required. Finally, you will be presented with a summary of all the parameters you previously introduced. Please note that dedicated IAM roles will be created to perform the scanning. These roles follow the \u0026ldquo;least privilege principle\u0026rdquo; to enforce maximum security.  Once you are happy with the plan, acknowledge it by marking the checkbox, and then press the Create stack button.   All ready! On the CloudFormation dashboard, you should see the template status is \u0026lsquo;CREATE_IN_PROGRESS\u0026rsquo;.\nThe creation process may take up to ten minutes. In the meantime you can continue with this workshop. You can later revisit the CloudFormation section in AWS to check the status of the deployment. It will show as “CREATE_COMPLETE” once the deployment has completed successfully.\n"
},
{
	"uri": "//localhost:1313/20_workshop_setup/24_setup_cloudtrail/242_install_cloudconnector.html",
	"title": "Installing the CloudConnector",
	"tags": [],
	"description": "",
	"content": " Steps To install this tool, we will be using a CloudFormation Template. Follow the steps below to install the Sysdig CloudConnector:\n Navigate to the CloudFormation template for Sysdig Cloud Connector deployment template. The template will preview in CloudFormation.  On the “Create stack” section, click the \u0026lsquo;Next\u0026rsquo; button to start setting up the template.  The “Specify stack details” section has no parameters for you to configure, so you can just press the Next button.  On _“Configure stack options_” screen, press the Next button. You can optionally add tag keys and values to the deployment, but no further configuration is required. Finally, you will be presented with a summary of all the parameters you previously introduced. Please note that dedicated IAM roles will be created to perform the scanning. These roles follow the \u0026ldquo;least privilege principle\u0026rdquo; to enforce maximum security.  Once you are happy with the plan, acknowledge it by marking the checkbox, and then press the Create stack button.   All ready! On the CloudFormation dashboard, you should see the template in _CREATE_INPROGRESS state.\nThe creation process may take up to ten minutes. In the meantime you can continue with this workshop. You can later revisit the CloudFormation section in AWS to check the status of the deployment. It will show as “CREATE_COMPLETE” once the deployment has completed successfully.\n"
},
{
	"uri": "//localhost:1313/25_setup_cloudtrail_integration/__242_install_cloudconnector.html",
	"title": "",
	"tags": [],
	"description": "",
	"content": " Installing the CloudConnector To install this tool, we will be using a CloudFormation Template. Follow the steps below to install the Sysdig CloudConnector:\n Navigate to the CloudFormation template for Sysdig Cloud Connector deployment template. The template will preview in CloudFormation.  On the “Create stack” section, click the \u0026lsquo;Next\u0026rsquo; button to start setting up the template.  The “Specify stack details” section has no parameters for you to configure, so you can just press the Next button.  On _“Configure stack options_” screen, press the Next button. You can optionally add tag keys and values to the deployment, but no further configuration is required. Finally, you will be presented with a summary of all the parameters you previously introduced. Please note that dedicated IAM roles will be created to perform the scanning. These roles follow the \u0026ldquo;least privilege principle\u0026rdquo; to enforce maximum security.  Once you are happy with the plan, acknowledge it by marking the checkbox, and then press the Create stack button.   All ready! On the CloudFormation dashboard, you should see the template status is \u0026lsquo;CREATE_IN_PROGRESS\u0026rsquo;.\nThe creation process may take up to ten minutes. In the meantime you can continue with this workshop. You can later revisit the CloudFormation section in AWS to check the status of the deployment. It will show as “CREATE_COMPLETE” once the deployment has completed successfully.\n"
},
{
	"uri": "//localhost:1313/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]